{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as numpy\n",
    "\n",
    "df=pd.read_csv('../data/modelling_dataset.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>channel_sales</th>\n",
       "      <th>cons_12m</th>\n",
       "      <th>cons_gas_12m</th>\n",
       "      <th>cons_last_month</th>\n",
       "      <th>forecast_cons_12m</th>\n",
       "      <th>forecast_cons_year</th>\n",
       "      <th>forecast_discount_energy</th>\n",
       "      <th>forecast_meter_rent_12m</th>\n",
       "      <th>forecast_price_energy_off_peak</th>\n",
       "      <th>forecast_price_energy_peak</th>\n",
       "      <th>...</th>\n",
       "      <th>var_6m_price_peak</th>\n",
       "      <th>var_6m_price_mid_peak</th>\n",
       "      <th>days_to_contract_end</th>\n",
       "      <th>days_from_last_modification</th>\n",
       "      <th>days_activ</th>\n",
       "      <th>days_renewal</th>\n",
       "      <th>average_yearly_price</th>\n",
       "      <th>total_cost</th>\n",
       "      <th>offpeak_diff_dec_january_energy</th>\n",
       "      <th>offpeak_diff_dec_january_power</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>channel_1</td>\n",
       "      <td>0</td>\n",
       "      <td>54946</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.78</td>\n",
       "      <td>0.114481</td>\n",
       "      <td>0.098142</td>\n",
       "      <td>...</td>\n",
       "      <td>9.953056e+01</td>\n",
       "      <td>4.423670e+01</td>\n",
       "      <td>138</td>\n",
       "      <td>89</td>\n",
       "      <td>958</td>\n",
       "      <td>220</td>\n",
       "      <td>0.099372</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020057</td>\n",
       "      <td>3.700961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>channel_2</td>\n",
       "      <td>4660</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>189.95</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.27</td>\n",
       "      <td>0.145711</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.217891e-03</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>214</td>\n",
       "      <td>2352</td>\n",
       "      <td>2352</td>\n",
       "      <td>151</td>\n",
       "      <td>0.117546</td>\n",
       "      <td>547.764166</td>\n",
       "      <td>-0.003767</td>\n",
       "      <td>0.177779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>channel_1</td>\n",
       "      <td>544</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>47.96</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.72</td>\n",
       "      <td>0.165794</td>\n",
       "      <td>0.087899</td>\n",
       "      <td>...</td>\n",
       "      <td>9.450150e-08</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>78</td>\n",
       "      <td>2114</td>\n",
       "      <td>2114</td>\n",
       "      <td>287</td>\n",
       "      <td>0.129466</td>\n",
       "      <td>70.429753</td>\n",
       "      <td>-0.004670</td>\n",
       "      <td>0.177779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>channel_2</td>\n",
       "      <td>1584</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>240.04</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.83</td>\n",
       "      <td>0.146694</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>61</td>\n",
       "      <td>2131</td>\n",
       "      <td>2131</td>\n",
       "      <td>304</td>\n",
       "      <td>0.151210</td>\n",
       "      <td>239.516772</td>\n",
       "      <td>-0.004547</td>\n",
       "      <td>0.177779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>channel_1</td>\n",
       "      <td>4425</td>\n",
       "      <td>0</td>\n",
       "      <td>526</td>\n",
       "      <td>445.75</td>\n",
       "      <td>526</td>\n",
       "      <td>0.0</td>\n",
       "      <td>131.73</td>\n",
       "      <td>0.116900</td>\n",
       "      <td>0.100015</td>\n",
       "      <td>...</td>\n",
       "      <td>2.896760e-06</td>\n",
       "      <td>4.860000e-10</td>\n",
       "      <td>38</td>\n",
       "      <td>2207</td>\n",
       "      <td>2207</td>\n",
       "      <td>326</td>\n",
       "      <td>0.100226</td>\n",
       "      <td>443.499681</td>\n",
       "      <td>-0.006192</td>\n",
       "      <td>0.162916</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  channel_sales  cons_12m  cons_gas_12m  cons_last_month  forecast_cons_12m  \\\n",
       "0     channel_1         0         54946                0               0.00   \n",
       "1     channel_2      4660             0                0             189.95   \n",
       "2     channel_1       544             0                0              47.96   \n",
       "3     channel_2      1584             0                0             240.04   \n",
       "4     channel_1      4425             0              526             445.75   \n",
       "\n",
       "   forecast_cons_year  forecast_discount_energy  forecast_meter_rent_12m  \\\n",
       "0                   0                       0.0                     1.78   \n",
       "1                   0                       0.0                    16.27   \n",
       "2                   0                       0.0                    38.72   \n",
       "3                   0                       0.0                    19.83   \n",
       "4                 526                       0.0                   131.73   \n",
       "\n",
       "   forecast_price_energy_off_peak  forecast_price_energy_peak  ...  \\\n",
       "0                        0.114481                    0.098142  ...   \n",
       "1                        0.145711                    0.000000  ...   \n",
       "2                        0.165794                    0.087899  ...   \n",
       "3                        0.146694                    0.000000  ...   \n",
       "4                        0.116900                    0.100015  ...   \n",
       "\n",
       "   var_6m_price_peak  var_6m_price_mid_peak  days_to_contract_end  \\\n",
       "0       9.953056e+01           4.423670e+01                   138   \n",
       "1       1.217891e-03           0.000000e+00                   214   \n",
       "2       9.450150e-08           0.000000e+00                    78   \n",
       "3       0.000000e+00           0.000000e+00                    61   \n",
       "4       2.896760e-06           4.860000e-10                    38   \n",
       "\n",
       "   days_from_last_modification  days_activ  days_renewal  \\\n",
       "0                           89         958           220   \n",
       "1                         2352        2352           151   \n",
       "2                         2114        2114           287   \n",
       "3                         2131        2131           304   \n",
       "4                         2207        2207           326   \n",
       "\n",
       "   average_yearly_price  total_cost  offpeak_diff_dec_january_energy  \\\n",
       "0              0.099372    0.000000                         0.020057   \n",
       "1              0.117546  547.764166                        -0.003767   \n",
       "2              0.129466   70.429753                        -0.004670   \n",
       "3              0.151210  239.516772                        -0.004547   \n",
       "4              0.100226  443.499681                        -0.006192   \n",
       "\n",
       "   offpeak_diff_dec_january_power  \n",
       "0                        3.700961  \n",
       "1                        0.177779  \n",
       "2                        0.177779  \n",
       "3                        0.177779  \n",
       "4                        0.162916  \n",
       "\n",
       "[5 rows x 46 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictive Model\n",
    "\n",
    "We are dealing with a classification problem. The given churn data tells that the customers status in next 3 month. We need to be able to predict accurately churn status of customers so that we can take action before they leave our services."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "channel_sales\n",
       "channel_1    9719\n",
       "channel_2    2503\n",
       "channel_3    1439\n",
       "channel_4     929\n",
       "channel_6      11\n",
       "channel_5       3\n",
       "channel_7       2\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Our dataset contains categorical columns, channel_sales and origin_up\n",
    "\n",
    "# Transform into categorical type\n",
    "df['channel_sales'] = df['channel_sales'].astype('category')\n",
    "\n",
    "# Let's see how many categories are within this column\n",
    "df['channel_sales'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last three channel is too low in value compared to size of dataset, thus will be dropped for the improvement of dimentionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cons_12m</th>\n",
       "      <th>cons_gas_12m</th>\n",
       "      <th>cons_last_month</th>\n",
       "      <th>forecast_cons_12m</th>\n",
       "      <th>forecast_cons_year</th>\n",
       "      <th>forecast_discount_energy</th>\n",
       "      <th>forecast_meter_rent_12m</th>\n",
       "      <th>forecast_price_energy_off_peak</th>\n",
       "      <th>forecast_price_energy_peak</th>\n",
       "      <th>forecast_price_pow_off_peak</th>\n",
       "      <th>...</th>\n",
       "      <th>days_activ</th>\n",
       "      <th>days_renewal</th>\n",
       "      <th>average_yearly_price</th>\n",
       "      <th>total_cost</th>\n",
       "      <th>offpeak_diff_dec_january_energy</th>\n",
       "      <th>offpeak_diff_dec_january_power</th>\n",
       "      <th>channel_sales_channel_1</th>\n",
       "      <th>channel_sales_channel_2</th>\n",
       "      <th>channel_sales_channel_3</th>\n",
       "      <th>channel_sales_channel_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>54946</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.78</td>\n",
       "      <td>0.114481</td>\n",
       "      <td>0.098142</td>\n",
       "      <td>40.606701</td>\n",
       "      <td>...</td>\n",
       "      <td>958</td>\n",
       "      <td>220</td>\n",
       "      <td>0.099372</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020057</td>\n",
       "      <td>3.700961</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4660</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>189.95</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.27</td>\n",
       "      <td>0.145711</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>44.311378</td>\n",
       "      <td>...</td>\n",
       "      <td>2352</td>\n",
       "      <td>151</td>\n",
       "      <td>0.117546</td>\n",
       "      <td>547.764166</td>\n",
       "      <td>-0.003767</td>\n",
       "      <td>0.177779</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>544</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>47.96</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.72</td>\n",
       "      <td>0.165794</td>\n",
       "      <td>0.087899</td>\n",
       "      <td>44.311378</td>\n",
       "      <td>...</td>\n",
       "      <td>2114</td>\n",
       "      <td>287</td>\n",
       "      <td>0.129466</td>\n",
       "      <td>70.429753</td>\n",
       "      <td>-0.004670</td>\n",
       "      <td>0.177779</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1584</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>240.04</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.83</td>\n",
       "      <td>0.146694</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>44.311378</td>\n",
       "      <td>...</td>\n",
       "      <td>2131</td>\n",
       "      <td>304</td>\n",
       "      <td>0.151210</td>\n",
       "      <td>239.516772</td>\n",
       "      <td>-0.004547</td>\n",
       "      <td>0.177779</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4425</td>\n",
       "      <td>0</td>\n",
       "      <td>526</td>\n",
       "      <td>445.75</td>\n",
       "      <td>526</td>\n",
       "      <td>0.0</td>\n",
       "      <td>131.73</td>\n",
       "      <td>0.116900</td>\n",
       "      <td>0.100015</td>\n",
       "      <td>40.606701</td>\n",
       "      <td>...</td>\n",
       "      <td>2207</td>\n",
       "      <td>326</td>\n",
       "      <td>0.100226</td>\n",
       "      <td>443.499681</td>\n",
       "      <td>-0.006192</td>\n",
       "      <td>0.162916</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   cons_12m  cons_gas_12m  cons_last_month  forecast_cons_12m  \\\n",
       "0         0         54946                0               0.00   \n",
       "1      4660             0                0             189.95   \n",
       "2       544             0                0              47.96   \n",
       "3      1584             0                0             240.04   \n",
       "4      4425             0              526             445.75   \n",
       "\n",
       "   forecast_cons_year  forecast_discount_energy  forecast_meter_rent_12m  \\\n",
       "0                   0                       0.0                     1.78   \n",
       "1                   0                       0.0                    16.27   \n",
       "2                   0                       0.0                    38.72   \n",
       "3                   0                       0.0                    19.83   \n",
       "4                 526                       0.0                   131.73   \n",
       "\n",
       "   forecast_price_energy_off_peak  forecast_price_energy_peak  \\\n",
       "0                        0.114481                    0.098142   \n",
       "1                        0.145711                    0.000000   \n",
       "2                        0.165794                    0.087899   \n",
       "3                        0.146694                    0.000000   \n",
       "4                        0.116900                    0.100015   \n",
       "\n",
       "   forecast_price_pow_off_peak  ...  days_activ  days_renewal  \\\n",
       "0                    40.606701  ...         958           220   \n",
       "1                    44.311378  ...        2352           151   \n",
       "2                    44.311378  ...        2114           287   \n",
       "3                    44.311378  ...        2131           304   \n",
       "4                    40.606701  ...        2207           326   \n",
       "\n",
       "   average_yearly_price  total_cost  offpeak_diff_dec_january_energy  \\\n",
       "0              0.099372    0.000000                         0.020057   \n",
       "1              0.117546  547.764166                        -0.003767   \n",
       "2              0.129466   70.429753                        -0.004670   \n",
       "3              0.151210  239.516772                        -0.004547   \n",
       "4              0.100226  443.499681                        -0.006192   \n",
       "\n",
       "   offpeak_diff_dec_january_power channel_sales_channel_1  \\\n",
       "0                        3.700961                    True   \n",
       "1                        0.177779                   False   \n",
       "2                        0.177779                    True   \n",
       "3                        0.177779                   False   \n",
       "4                        0.162916                    True   \n",
       "\n",
       "   channel_sales_channel_2  channel_sales_channel_3  channel_sales_channel_4  \n",
       "0                    False                    False                    False  \n",
       "1                     True                    False                    False  \n",
       "2                    False                    False                    False  \n",
       "3                     True                    False                    False  \n",
       "4                    False                    False                    False  \n",
       "\n",
       "[5 rows x 49 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.get_dummies(df, columns=['channel_sales'])\n",
    "df = df.drop(columns=['channel_sales_channel_5', 'channel_sales_channel_6', 'channel_sales_channel_7'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "origin_up\n",
       "origin_1    7137\n",
       "origin_2    4305\n",
       "origin_3    3161\n",
       "origin_4       2\n",
       "origin_5       1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Our dataset contains categorical columns, channel_sales and origin_up\n",
    "\n",
    "# Transform into categorical type\n",
    "df['origin_up'] = df['origin_up'].astype('category')\n",
    "\n",
    "# Let's see how many categories are within this column\n",
    "df['origin_up'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cons_12m</th>\n",
       "      <th>cons_gas_12m</th>\n",
       "      <th>cons_last_month</th>\n",
       "      <th>forecast_cons_12m</th>\n",
       "      <th>forecast_cons_year</th>\n",
       "      <th>forecast_discount_energy</th>\n",
       "      <th>forecast_meter_rent_12m</th>\n",
       "      <th>forecast_price_energy_off_peak</th>\n",
       "      <th>forecast_price_energy_peak</th>\n",
       "      <th>forecast_price_pow_off_peak</th>\n",
       "      <th>...</th>\n",
       "      <th>total_cost</th>\n",
       "      <th>offpeak_diff_dec_january_energy</th>\n",
       "      <th>offpeak_diff_dec_january_power</th>\n",
       "      <th>channel_sales_channel_1</th>\n",
       "      <th>channel_sales_channel_2</th>\n",
       "      <th>channel_sales_channel_3</th>\n",
       "      <th>channel_sales_channel_4</th>\n",
       "      <th>origin_up_origin_1</th>\n",
       "      <th>origin_up_origin_2</th>\n",
       "      <th>origin_up_origin_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>54946</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.78</td>\n",
       "      <td>0.114481</td>\n",
       "      <td>0.098142</td>\n",
       "      <td>40.606701</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020057</td>\n",
       "      <td>3.700961</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4660</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>189.95</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.27</td>\n",
       "      <td>0.145711</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>44.311378</td>\n",
       "      <td>...</td>\n",
       "      <td>547.764166</td>\n",
       "      <td>-0.003767</td>\n",
       "      <td>0.177779</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>544</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>47.96</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.72</td>\n",
       "      <td>0.165794</td>\n",
       "      <td>0.087899</td>\n",
       "      <td>44.311378</td>\n",
       "      <td>...</td>\n",
       "      <td>70.429753</td>\n",
       "      <td>-0.004670</td>\n",
       "      <td>0.177779</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1584</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>240.04</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.83</td>\n",
       "      <td>0.146694</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>44.311378</td>\n",
       "      <td>...</td>\n",
       "      <td>239.516772</td>\n",
       "      <td>-0.004547</td>\n",
       "      <td>0.177779</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4425</td>\n",
       "      <td>0</td>\n",
       "      <td>526</td>\n",
       "      <td>445.75</td>\n",
       "      <td>526</td>\n",
       "      <td>0.0</td>\n",
       "      <td>131.73</td>\n",
       "      <td>0.116900</td>\n",
       "      <td>0.100015</td>\n",
       "      <td>40.606701</td>\n",
       "      <td>...</td>\n",
       "      <td>443.499681</td>\n",
       "      <td>-0.006192</td>\n",
       "      <td>0.162916</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   cons_12m  cons_gas_12m  cons_last_month  forecast_cons_12m  \\\n",
       "0         0         54946                0               0.00   \n",
       "1      4660             0                0             189.95   \n",
       "2       544             0                0              47.96   \n",
       "3      1584             0                0             240.04   \n",
       "4      4425             0              526             445.75   \n",
       "\n",
       "   forecast_cons_year  forecast_discount_energy  forecast_meter_rent_12m  \\\n",
       "0                   0                       0.0                     1.78   \n",
       "1                   0                       0.0                    16.27   \n",
       "2                   0                       0.0                    38.72   \n",
       "3                   0                       0.0                    19.83   \n",
       "4                 526                       0.0                   131.73   \n",
       "\n",
       "   forecast_price_energy_off_peak  forecast_price_energy_peak  \\\n",
       "0                        0.114481                    0.098142   \n",
       "1                        0.145711                    0.000000   \n",
       "2                        0.165794                    0.087899   \n",
       "3                        0.146694                    0.000000   \n",
       "4                        0.116900                    0.100015   \n",
       "\n",
       "   forecast_price_pow_off_peak  ...  total_cost  \\\n",
       "0                    40.606701  ...    0.000000   \n",
       "1                    44.311378  ...  547.764166   \n",
       "2                    44.311378  ...   70.429753   \n",
       "3                    44.311378  ...  239.516772   \n",
       "4                    40.606701  ...  443.499681   \n",
       "\n",
       "   offpeak_diff_dec_january_energy  offpeak_diff_dec_january_power  \\\n",
       "0                         0.020057                        3.700961   \n",
       "1                        -0.003767                        0.177779   \n",
       "2                        -0.004670                        0.177779   \n",
       "3                        -0.004547                        0.177779   \n",
       "4                        -0.006192                        0.162916   \n",
       "\n",
       "   channel_sales_channel_1  channel_sales_channel_2  channel_sales_channel_3  \\\n",
       "0                     True                    False                    False   \n",
       "1                    False                     True                    False   \n",
       "2                     True                    False                    False   \n",
       "3                    False                     True                    False   \n",
       "4                     True                    False                    False   \n",
       "\n",
       "   channel_sales_channel_4  origin_up_origin_1  origin_up_origin_2  \\\n",
       "0                    False                True               False   \n",
       "1                    False               False                True   \n",
       "2                    False               False                True   \n",
       "3                    False               False                True   \n",
       "4                    False               False                True   \n",
       "\n",
       "   origin_up_origin_3  \n",
       "0               False  \n",
       "1               False  \n",
       "2               False  \n",
       "3               False  \n",
       "4               False  \n",
       "\n",
       "[5 rows x 51 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.get_dummies(df, columns=['origin_up'])\n",
    "df = df.drop(columns=['origin_up_origin_4', 'origin_up_origin_5'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score, \n",
    "                             f1_score, confusion_matrix, roc_auc_score)\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def classification_report_with_confusion_matrix(y_true, y_pred):    \n",
    "    # Confusion Matrix\n",
    "    conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    # Plot Confusion Matrix\n",
    "    plt.figure(figsize=(4, 3))\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap=plt.cm.Blues, cbar=False)\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First Model: Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(bootstrap=False, class_weight={0: 1, 1: 10},\n",
       "                       n_estimators=250)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(bootstrap=False, class_weight={0: 1, 1: 10},\n",
       "                       n_estimators=250)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(bootstrap=False, class_weight={0: 1, 1: 10},\n",
       "                       n_estimators=250)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "X =df.drop(columns='churn',axis=1)\n",
    "y=df['churn']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "model = RandomForestClassifier(class_weight={0: 1, 1: 10},n_estimators=250,bootstrap=False) # Add parameters to the model!\n",
    "model.fit(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.90      0.95      2893\n",
      "           1       0.08      0.83      0.14        29\n",
      "\n",
      "    accuracy                           0.90      2922\n",
      "   macro avg       0.54      0.87      0.55      2922\n",
      "weighted avg       0.99      0.90      0.94      2922\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "y_pred=model.predict(X_test)\n",
    "print(classification_report(y_pred,y_test))\n",
    "classification_report_with_confusion_matrix(y_test,y_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second Model: Neural Network for Binary Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Gradient-Based Algorithms standartazing is important step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X =df.drop(columns='churn',axis=1)\n",
    "y=df['churn']\n",
    "\n",
    "# Create a StandardScaler object\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler to your data and transform the data\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "# Setting GPU for computation power. Faster results.\n",
    "gpus=tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)\n",
    "#Check\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 128)               6528      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                4128      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,689\n",
      "Trainable params: 10,689\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/150\n",
      "234/234 [==============================] - 8s 6ms/step - loss: 0.6770 - accuracy: 0.5534 - val_loss: 0.6423 - val_accuracy: 0.6003\n",
      "Epoch 2/150\n",
      "234/234 [==============================] - 1s 4ms/step - loss: 0.6452 - accuracy: 0.5987 - val_loss: 0.6940 - val_accuracy: 0.5255\n",
      "Epoch 3/150\n",
      "234/234 [==============================] - 1s 4ms/step - loss: 0.6341 - accuracy: 0.6106 - val_loss: 0.6728 - val_accuracy: 0.5802\n",
      "Epoch 4/150\n",
      "234/234 [==============================] - 1s 4ms/step - loss: 0.6213 - accuracy: 0.6364 - val_loss: 0.6303 - val_accuracy: 0.6243\n",
      "Epoch 5/150\n",
      "234/234 [==============================] - 1s 4ms/step - loss: 0.6147 - accuracy: 0.6483 - val_loss: 0.6346 - val_accuracy: 0.6213\n",
      "Epoch 6/150\n",
      "234/234 [==============================] - 1s 4ms/step - loss: 0.6009 - accuracy: 0.6405 - val_loss: 0.5727 - val_accuracy: 0.7039\n",
      "Epoch 7/150\n",
      "234/234 [==============================] - 1s 4ms/step - loss: 0.5938 - accuracy: 0.6649 - val_loss: 0.6069 - val_accuracy: 0.6466\n",
      "Epoch 8/150\n",
      "234/234 [==============================] - 1s 4ms/step - loss: 0.5863 - accuracy: 0.6720 - val_loss: 0.6352 - val_accuracy: 0.6217\n",
      "Epoch 9/150\n",
      "234/234 [==============================] - 1s 4ms/step - loss: 0.5769 - accuracy: 0.6763 - val_loss: 0.6061 - val_accuracy: 0.6316\n",
      "Epoch 10/150\n",
      "234/234 [==============================] - 1s 4ms/step - loss: 0.5652 - accuracy: 0.6837 - val_loss: 0.6302 - val_accuracy: 0.6192\n",
      "Epoch 11/150\n",
      "234/234 [==============================] - 1s 4ms/step - loss: 0.5581 - accuracy: 0.6895 - val_loss: 0.6114 - val_accuracy: 0.6461\n",
      "Epoch 12/150\n",
      "234/234 [==============================] - 1s 4ms/step - loss: 0.5507 - accuracy: 0.6975 - val_loss: 0.6773 - val_accuracy: 0.5772\n",
      "Epoch 13/150\n",
      "234/234 [==============================] - 1s 4ms/step - loss: 0.5413 - accuracy: 0.6970 - val_loss: 0.6422 - val_accuracy: 0.6209\n",
      "Epoch 14/150\n",
      "234/234 [==============================] - 1s 4ms/step - loss: 0.5309 - accuracy: 0.7124 - val_loss: 0.6201 - val_accuracy: 0.6414\n",
      "Epoch 15/150\n",
      "234/234 [==============================] - 1s 4ms/step - loss: 0.5236 - accuracy: 0.7204 - val_loss: 0.5676 - val_accuracy: 0.7090\n",
      "Epoch 16/150\n",
      "234/234 [==============================] - 1s 4ms/step - loss: 0.5141 - accuracy: 0.7261 - val_loss: 0.6658 - val_accuracy: 0.6029\n",
      "Epoch 17/150\n",
      "234/234 [==============================] - 1s 4ms/step - loss: 0.5097 - accuracy: 0.7227 - val_loss: 0.5734 - val_accuracy: 0.6906\n",
      "Epoch 18/150\n",
      "234/234 [==============================] - 1s 4ms/step - loss: 0.5033 - accuracy: 0.7402 - val_loss: 0.6381 - val_accuracy: 0.6269\n",
      "Epoch 19/150\n",
      "234/234 [==============================] - 1s 4ms/step - loss: 0.4958 - accuracy: 0.7390 - val_loss: 0.5892 - val_accuracy: 0.6932\n",
      "Epoch 20/150\n",
      "234/234 [==============================] - 1s 4ms/step - loss: 0.4829 - accuracy: 0.7491 - val_loss: 0.6569 - val_accuracy: 0.6418\n",
      "Epoch 21/150\n",
      "234/234 [==============================] - 1s 4ms/step - loss: 0.4794 - accuracy: 0.7448 - val_loss: 0.6081 - val_accuracy: 0.6902\n",
      "Epoch 22/150\n",
      "234/234 [==============================] - 1s 4ms/step - loss: 0.4694 - accuracy: 0.7584 - val_loss: 0.5443 - val_accuracy: 0.7309\n",
      "Epoch 23/150\n",
      "234/234 [==============================] - 1s 4ms/step - loss: 0.4723 - accuracy: 0.7605 - val_loss: 0.6077 - val_accuracy: 0.6996\n",
      "Epoch 24/150\n",
      "234/234 [==============================] - 1s 4ms/step - loss: 0.4633 - accuracy: 0.7643 - val_loss: 0.6882 - val_accuracy: 0.6243\n",
      "Epoch 25/150\n",
      "234/234 [==============================] - 1s 4ms/step - loss: 0.4502 - accuracy: 0.7682 - val_loss: 0.5735 - val_accuracy: 0.7107\n",
      "Epoch 26/150\n",
      "234/234 [==============================] - 1s 4ms/step - loss: 0.4481 - accuracy: 0.7699 - val_loss: 0.5694 - val_accuracy: 0.7231\n",
      "Epoch 27/150\n",
      "234/234 [==============================] - 1s 4ms/step - loss: 0.4404 - accuracy: 0.7749 - val_loss: 0.5717 - val_accuracy: 0.7180\n",
      "Epoch 28/150\n",
      "234/234 [==============================] - 1s 4ms/step - loss: 0.4359 - accuracy: 0.7789 - val_loss: 0.6091 - val_accuracy: 0.6859\n",
      "Epoch 29/150\n",
      "234/234 [==============================] - 1s 4ms/step - loss: 0.4250 - accuracy: 0.7782 - val_loss: 0.6405 - val_accuracy: 0.6722\n",
      "Epoch 30/150\n",
      "234/234 [==============================] - 1s 3ms/step - loss: 0.4207 - accuracy: 0.7898 - val_loss: 0.7132 - val_accuracy: 0.5969\n",
      "Epoch 31/150\n",
      "234/234 [==============================] - 1s 4ms/step - loss: 0.4229 - accuracy: 0.7798 - val_loss: 0.5539 - val_accuracy: 0.7368\n",
      "Epoch 32/150\n",
      "234/234 [==============================] - 1s 4ms/step - loss: 0.4131 - accuracy: 0.7938 - val_loss: 0.6182 - val_accuracy: 0.6765\n",
      "Epoch 33/150\n",
      "234/234 [==============================] - 1s 3ms/step - loss: 0.4056 - accuracy: 0.7932 - val_loss: 0.5781 - val_accuracy: 0.7206\n",
      "Epoch 34/150\n",
      "234/234 [==============================] - 1s 4ms/step - loss: 0.3970 - accuracy: 0.8027 - val_loss: 0.5504 - val_accuracy: 0.7424\n",
      "Epoch 35/150\n",
      "234/234 [==============================] - 1s 4ms/step - loss: 0.3992 - accuracy: 0.8007 - val_loss: 0.5892 - val_accuracy: 0.7244\n",
      "Epoch 36/150\n",
      "234/234 [==============================] - 1s 4ms/step - loss: 0.3966 - accuracy: 0.8038 - val_loss: 0.5755 - val_accuracy: 0.7167\n",
      "Epoch 37/150\n",
      "234/234 [==============================] - 1s 4ms/step - loss: 0.3859 - accuracy: 0.8019 - val_loss: 0.6162 - val_accuracy: 0.6958\n",
      "Epoch 38/150\n",
      "234/234 [==============================] - 1s 4ms/step - loss: 0.3852 - accuracy: 0.8067 - val_loss: 0.5466 - val_accuracy: 0.7638\n",
      "Epoch 39/150\n",
      "234/234 [==============================] - 1s 4ms/step - loss: 0.3810 - accuracy: 0.8113 - val_loss: 0.5032 - val_accuracy: 0.7980\n",
      "Epoch 40/150\n",
      "234/234 [==============================] - 1s 4ms/step - loss: 0.3710 - accuracy: 0.8166 - val_loss: 0.5995 - val_accuracy: 0.7184\n",
      "Epoch 41/150\n",
      "234/234 [==============================] - 1s 4ms/step - loss: 0.3684 - accuracy: 0.8133 - val_loss: 0.5793 - val_accuracy: 0.7373\n",
      "Epoch 42/150\n",
      "234/234 [==============================] - 1s 4ms/step - loss: 0.3687 - accuracy: 0.8191 - val_loss: 0.7823 - val_accuracy: 0.6068\n",
      "Epoch 43/150\n",
      "234/234 [==============================] - 1s 4ms/step - loss: 0.3602 - accuracy: 0.8197 - val_loss: 0.6257 - val_accuracy: 0.7069\n",
      "Epoch 44/150\n",
      "234/234 [==============================] - 1s 4ms/step - loss: 0.3611 - accuracy: 0.8174 - val_loss: 0.6418 - val_accuracy: 0.6812\n",
      "Epoch 45/150\n",
      "234/234 [==============================] - 1s 4ms/step - loss: 0.3556 - accuracy: 0.8158 - val_loss: 0.5713 - val_accuracy: 0.7398\n",
      "Epoch 46/150\n",
      "234/234 [==============================] - 1s 4ms/step - loss: 0.3514 - accuracy: 0.8210 - val_loss: 0.4986 - val_accuracy: 0.8015\n",
      "Epoch 47/150\n",
      "234/234 [==============================] - 1s 4ms/step - loss: 0.3489 - accuracy: 0.8253 - val_loss: 0.5734 - val_accuracy: 0.7561\n",
      "Epoch 48/150\n",
      "234/234 [==============================] - 1s 4ms/step - loss: 0.3352 - accuracy: 0.8360 - val_loss: 0.5825 - val_accuracy: 0.7458\n",
      "Epoch 49/150\n",
      "234/234 [==============================] - 1s 4ms/step - loss: 0.3379 - accuracy: 0.8283 - val_loss: 0.5516 - val_accuracy: 0.7681\n",
      "Epoch 50/150\n",
      "234/234 [==============================] - 1s 4ms/step - loss: 0.3336 - accuracy: 0.8358 - val_loss: 0.6059 - val_accuracy: 0.7458\n",
      "Epoch 51/150\n",
      "234/234 [==============================] - 1s 4ms/step - loss: 0.3321 - accuracy: 0.8332 - val_loss: 0.6137 - val_accuracy: 0.7317\n",
      "Epoch 52/150\n",
      "234/234 [==============================] - 1s 4ms/step - loss: 0.3243 - accuracy: 0.8405 - val_loss: 0.5700 - val_accuracy: 0.7480\n",
      "Epoch 53/150\n",
      "234/234 [==============================] - 1s 4ms/step - loss: 0.3319 - accuracy: 0.8390 - val_loss: 0.5404 - val_accuracy: 0.7856\n",
      "Epoch 54/150\n",
      "234/234 [==============================] - 1s 4ms/step - loss: 0.3256 - accuracy: 0.8377 - val_loss: 0.5502 - val_accuracy: 0.7831\n",
      "Epoch 55/150\n",
      "234/234 [==============================] - 1s 4ms/step - loss: 0.3250 - accuracy: 0.8351 - val_loss: 0.5668 - val_accuracy: 0.7728\n",
      "Epoch 56/150\n",
      "234/234 [==============================] - 1s 4ms/step - loss: 0.3195 - accuracy: 0.8471 - val_loss: 0.6482 - val_accuracy: 0.7202\n",
      "Epoch 57/150\n",
      "234/234 [==============================] - 1s 4ms/step - loss: 0.3130 - accuracy: 0.8462 - val_loss: 0.5905 - val_accuracy: 0.7518\n",
      "Epoch 58/150\n",
      "234/234 [==============================] - 1s 4ms/step - loss: 0.3159 - accuracy: 0.8482 - val_loss: 0.6062 - val_accuracy: 0.7604\n",
      "Epoch 59/150\n",
      "234/234 [==============================] - 1s 4ms/step - loss: 0.3090 - accuracy: 0.8419 - val_loss: 0.5699 - val_accuracy: 0.7813\n",
      "Epoch 60/150\n",
      "234/234 [==============================] - 1s 4ms/step - loss: 0.3066 - accuracy: 0.8451 - val_loss: 0.5711 - val_accuracy: 0.7831\n",
      "Epoch 61/150\n",
      "234/234 [==============================] - 1s 4ms/step - loss: 0.3058 - accuracy: 0.8500 - val_loss: 0.6113 - val_accuracy: 0.7599\n",
      "Epoch 62/150\n",
      "234/234 [==============================] - 1s 4ms/step - loss: 0.2981 - accuracy: 0.8566 - val_loss: 0.5314 - val_accuracy: 0.8207\n",
      "Epoch 63/150\n",
      "234/234 [==============================] - 1s 4ms/step - loss: 0.2943 - accuracy: 0.8537 - val_loss: 0.5898 - val_accuracy: 0.7865\n",
      "Epoch 64/150\n",
      "234/234 [==============================] - 1s 4ms/step - loss: 0.2942 - accuracy: 0.8600 - val_loss: 0.7063 - val_accuracy: 0.6958\n",
      "Epoch 65/150\n",
      "234/234 [==============================] - 1s 4ms/step - loss: 0.2920 - accuracy: 0.8574 - val_loss: 0.6445 - val_accuracy: 0.7394\n",
      "Epoch 66/150\n",
      "234/234 [==============================] - 1s 4ms/step - loss: 0.2847 - accuracy: 0.8589 - val_loss: 0.5677 - val_accuracy: 0.7942\n",
      "Epoch 67/150\n",
      "234/234 [==============================] - 1s 4ms/step - loss: 0.2813 - accuracy: 0.8626 - val_loss: 0.5831 - val_accuracy: 0.7878\n",
      "Epoch 68/150\n",
      "234/234 [==============================] - 1s 4ms/step - loss: 0.2815 - accuracy: 0.8609 - val_loss: 0.6606 - val_accuracy: 0.7364\n",
      "Epoch 69/150\n",
      "234/234 [==============================] - 1s 4ms/step - loss: 0.2864 - accuracy: 0.8631 - val_loss: 0.5916 - val_accuracy: 0.8019\n",
      "Epoch 70/150\n",
      "234/234 [==============================] - 1s 4ms/step - loss: 0.2819 - accuracy: 0.8631 - val_loss: 0.6201 - val_accuracy: 0.7852\n",
      "Epoch 71/150\n",
      "234/234 [==============================] - 1s 4ms/step - loss: 0.2771 - accuracy: 0.8683 - val_loss: 0.6514 - val_accuracy: 0.7398\n",
      "Epoch 72/150\n",
      "234/234 [==============================] - 1s 4ms/step - loss: 0.2698 - accuracy: 0.8698 - val_loss: 0.6223 - val_accuracy: 0.7779\n",
      "Epoch 73/150\n",
      "234/234 [==============================] - 1s 4ms/step - loss: 0.2692 - accuracy: 0.8685 - val_loss: 0.6826 - val_accuracy: 0.7257\n",
      "Epoch 74/150\n",
      "234/234 [==============================] - 1s 4ms/step - loss: 0.2690 - accuracy: 0.8707 - val_loss: 0.5982 - val_accuracy: 0.8040\n",
      "Epoch 75/150\n",
      "234/234 [==============================] - 1s 3ms/step - loss: 0.2710 - accuracy: 0.8712 - val_loss: 0.7000 - val_accuracy: 0.7445\n",
      "Epoch 76/150\n",
      "234/234 [==============================] - 1s 3ms/step - loss: 0.2639 - accuracy: 0.8729 - val_loss: 0.6643 - val_accuracy: 0.7681\n",
      "Epoch 77/150\n",
      "234/234 [==============================] - 1s 3ms/step - loss: 0.2669 - accuracy: 0.8723 - val_loss: 0.7129 - val_accuracy: 0.7441\n",
      "Epoch 78/150\n",
      "234/234 [==============================] - 1s 3ms/step - loss: 0.2687 - accuracy: 0.8738 - val_loss: 0.6782 - val_accuracy: 0.7535\n",
      "Epoch 79/150\n",
      "234/234 [==============================] - 1s 4ms/step - loss: 0.2670 - accuracy: 0.8676 - val_loss: 0.6005 - val_accuracy: 0.8130\n",
      "Epoch 80/150\n",
      "234/234 [==============================] - 1s 4ms/step - loss: 0.2529 - accuracy: 0.8787 - val_loss: 0.6116 - val_accuracy: 0.8066\n",
      "Epoch 81/150\n",
      "234/234 [==============================] - 1s 3ms/step - loss: 0.2641 - accuracy: 0.8725 - val_loss: 0.6640 - val_accuracy: 0.7706\n",
      "Epoch 82/150\n",
      "234/234 [==============================] - 1s 3ms/step - loss: 0.2468 - accuracy: 0.8831 - val_loss: 0.7285 - val_accuracy: 0.7227\n",
      "Epoch 83/150\n",
      "234/234 [==============================] - 1s 4ms/step - loss: 0.2520 - accuracy: 0.8749 - val_loss: 0.7171 - val_accuracy: 0.7317\n",
      "Epoch 84/150\n",
      "234/234 [==============================] - 1s 3ms/step - loss: 0.2534 - accuracy: 0.8746 - val_loss: 0.6834 - val_accuracy: 0.7741\n",
      "Epoch 85/150\n",
      "234/234 [==============================] - 1s 3ms/step - loss: 0.2590 - accuracy: 0.8743 - val_loss: 0.6447 - val_accuracy: 0.7818\n",
      "Epoch 86/150\n",
      "234/234 [==============================] - 1s 4ms/step - loss: 0.2495 - accuracy: 0.8823 - val_loss: 0.7431 - val_accuracy: 0.7219\n",
      "Epoch 87/150\n",
      "234/234 [==============================] - 1s 3ms/step - loss: 0.2489 - accuracy: 0.8782 - val_loss: 0.7672 - val_accuracy: 0.7172\n",
      "Epoch 88/150\n",
      "234/234 [==============================] - 1s 3ms/step - loss: 0.2470 - accuracy: 0.8806 - val_loss: 0.6367 - val_accuracy: 0.7989\n",
      "Epoch 89/150\n",
      "234/234 [==============================] - 1s 4ms/step - loss: 0.2347 - accuracy: 0.8869 - val_loss: 0.6103 - val_accuracy: 0.8207\n",
      "Epoch 90/150\n",
      "234/234 [==============================] - 1s 3ms/step - loss: 0.2371 - accuracy: 0.8857 - val_loss: 0.7469 - val_accuracy: 0.7326\n",
      "Epoch 91/150\n",
      "234/234 [==============================] - 1s 4ms/step - loss: 0.2387 - accuracy: 0.8833 - val_loss: 0.6799 - val_accuracy: 0.7843\n",
      "Epoch 92/150\n",
      "234/234 [==============================] - 1s 4ms/step - loss: 0.2344 - accuracy: 0.8886 - val_loss: 0.6350 - val_accuracy: 0.8079\n",
      "Epoch 93/150\n",
      "234/234 [==============================] - 1s 4ms/step - loss: 0.2366 - accuracy: 0.8870 - val_loss: 0.6575 - val_accuracy: 0.7946\n",
      "Epoch 94/150\n",
      "234/234 [==============================] - 1s 4ms/step - loss: 0.2365 - accuracy: 0.8845 - val_loss: 0.6410 - val_accuracy: 0.8122\n",
      "Epoch 95/150\n",
      "234/234 [==============================] - 1s 3ms/step - loss: 0.2384 - accuracy: 0.8876 - val_loss: 0.6276 - val_accuracy: 0.8284\n",
      "Epoch 96/150\n",
      "234/234 [==============================] - 1s 4ms/step - loss: 0.2256 - accuracy: 0.8854 - val_loss: 0.6630 - val_accuracy: 0.7972\n",
      "Epoch 97/150\n",
      "234/234 [==============================] - 1s 3ms/step - loss: 0.2282 - accuracy: 0.8898 - val_loss: 0.6903 - val_accuracy: 0.7955\n",
      "Epoch 98/150\n",
      "234/234 [==============================] - 1s 4ms/step - loss: 0.2281 - accuracy: 0.8898 - val_loss: 0.7252 - val_accuracy: 0.7788\n",
      "Epoch 99/150\n",
      "234/234 [==============================] - 1s 4ms/step - loss: 0.2241 - accuracy: 0.8918 - val_loss: 0.6604 - val_accuracy: 0.8053\n",
      "Epoch 100/150\n",
      "234/234 [==============================] - 1s 3ms/step - loss: 0.2307 - accuracy: 0.8887 - val_loss: 0.6864 - val_accuracy: 0.8151\n",
      "Epoch 101/150\n",
      "234/234 [==============================] - 1s 3ms/step - loss: 0.2307 - accuracy: 0.8893 - val_loss: 0.6951 - val_accuracy: 0.8139\n",
      "Epoch 102/150\n",
      "234/234 [==============================] - 1s 4ms/step - loss: 0.2286 - accuracy: 0.8887 - val_loss: 0.6932 - val_accuracy: 0.7861\n",
      "Epoch 103/150\n",
      "234/234 [==============================] - 1s 3ms/step - loss: 0.2269 - accuracy: 0.8910 - val_loss: 0.7873 - val_accuracy: 0.7398\n",
      "Epoch 104/150\n",
      "234/234 [==============================] - 1s 3ms/step - loss: 0.2196 - accuracy: 0.8913 - val_loss: 0.6490 - val_accuracy: 0.8151\n",
      "Epoch 105/150\n",
      "234/234 [==============================] - 1s 4ms/step - loss: 0.2141 - accuracy: 0.8955 - val_loss: 0.6724 - val_accuracy: 0.8207\n",
      "Epoch 106/150\n",
      "234/234 [==============================] - 1s 3ms/step - loss: 0.2138 - accuracy: 0.8979 - val_loss: 0.6940 - val_accuracy: 0.8100\n",
      "Epoch 107/150\n",
      "234/234 [==============================] - 1s 4ms/step - loss: 0.2141 - accuracy: 0.8985 - val_loss: 0.7388 - val_accuracy: 0.7668\n",
      "Epoch 108/150\n",
      "234/234 [==============================] - 1s 4ms/step - loss: 0.2135 - accuracy: 0.8956 - val_loss: 0.7310 - val_accuracy: 0.7822\n",
      "Epoch 109/150\n",
      "234/234 [==============================] - 1s 4ms/step - loss: 0.2103 - accuracy: 0.8990 - val_loss: 0.7230 - val_accuracy: 0.7972\n",
      "Epoch 110/150\n",
      "234/234 [==============================] - 1s 4ms/step - loss: 0.2140 - accuracy: 0.8996 - val_loss: 0.7565 - val_accuracy: 0.7796\n",
      "Epoch 111/150\n",
      "234/234 [==============================] - 1s 4ms/step - loss: 0.2142 - accuracy: 0.8975 - val_loss: 0.6676 - val_accuracy: 0.8250\n",
      "Epoch 112/150\n",
      "234/234 [==============================] - 1s 3ms/step - loss: 0.2307 - accuracy: 0.9005 - val_loss: 0.6996 - val_accuracy: 0.8207\n",
      "Epoch 113/150\n",
      "234/234 [==============================] - 1s 4ms/step - loss: 0.2087 - accuracy: 0.9015 - val_loss: 0.7390 - val_accuracy: 0.7950\n",
      "Epoch 114/150\n",
      "234/234 [==============================] - 1s 4ms/step - loss: 0.2130 - accuracy: 0.9026 - val_loss: 0.7309 - val_accuracy: 0.8023\n",
      "Epoch 115/150\n",
      "234/234 [==============================] - 1s 4ms/step - loss: 0.2048 - accuracy: 0.8990 - val_loss: 0.7419 - val_accuracy: 0.7861\n",
      "Epoch 116/150\n",
      "234/234 [==============================] - 1s 4ms/step - loss: 0.2091 - accuracy: 0.9002 - val_loss: 0.7321 - val_accuracy: 0.7912\n",
      "Epoch 117/150\n",
      "234/234 [==============================] - 1s 4ms/step - loss: 0.2010 - accuracy: 0.9040 - val_loss: 0.6947 - val_accuracy: 0.8276\n",
      "Epoch 118/150\n",
      "234/234 [==============================] - 1s 4ms/step - loss: 0.2107 - accuracy: 0.9000 - val_loss: 0.7207 - val_accuracy: 0.8267\n",
      "Epoch 119/150\n",
      "234/234 [==============================] - 1s 4ms/step - loss: 0.2026 - accuracy: 0.9030 - val_loss: 0.7747 - val_accuracy: 0.7779\n",
      "Epoch 120/150\n",
      "234/234 [==============================] - 1s 4ms/step - loss: 0.2016 - accuracy: 0.9048 - val_loss: 0.7185 - val_accuracy: 0.8032\n",
      "Epoch 121/150\n",
      "234/234 [==============================] - 1s 4ms/step - loss: 0.1994 - accuracy: 0.9008 - val_loss: 0.8101 - val_accuracy: 0.7698\n",
      "Epoch 122/150\n",
      "234/234 [==============================] - 1s 4ms/step - loss: 0.2011 - accuracy: 0.9045 - val_loss: 0.7551 - val_accuracy: 0.8006\n",
      "Epoch 123/150\n",
      "234/234 [==============================] - 1s 4ms/step - loss: 0.2024 - accuracy: 0.9046 - val_loss: 0.7640 - val_accuracy: 0.7818\n",
      "Epoch 124/150\n",
      "234/234 [==============================] - 1s 3ms/step - loss: 0.1945 - accuracy: 0.9067 - val_loss: 0.6889 - val_accuracy: 0.8528\n",
      "Epoch 125/150\n",
      "234/234 [==============================] - 1s 3ms/step - loss: 0.1985 - accuracy: 0.9054 - val_loss: 0.7503 - val_accuracy: 0.8032\n",
      "Epoch 126/150\n",
      "234/234 [==============================] - 1s 4ms/step - loss: 0.2039 - accuracy: 0.9052 - val_loss: 0.7577 - val_accuracy: 0.8045\n",
      "Epoch 127/150\n",
      "234/234 [==============================] - 1s 4ms/step - loss: 0.1904 - accuracy: 0.9103 - val_loss: 0.7169 - val_accuracy: 0.8323\n",
      "Epoch 128/150\n",
      "234/234 [==============================] - 1s 4ms/step - loss: 0.1895 - accuracy: 0.9057 - val_loss: 0.7271 - val_accuracy: 0.8340\n",
      "Epoch 129/150\n",
      "234/234 [==============================] - 1s 4ms/step - loss: 0.1874 - accuracy: 0.9112 - val_loss: 0.7409 - val_accuracy: 0.8190\n",
      "Epoch 130/150\n",
      "234/234 [==============================] - 1s 4ms/step - loss: 0.1870 - accuracy: 0.9143 - val_loss: 0.7779 - val_accuracy: 0.7865\n",
      "Epoch 131/150\n",
      "234/234 [==============================] - 1s 4ms/step - loss: 0.1942 - accuracy: 0.9060 - val_loss: 0.8112 - val_accuracy: 0.7792\n",
      "Epoch 132/150\n",
      "234/234 [==============================] - 1s 4ms/step - loss: 0.2020 - accuracy: 0.9099 - val_loss: 0.7577 - val_accuracy: 0.8032\n",
      "Epoch 133/150\n",
      "234/234 [==============================] - 1s 4ms/step - loss: 0.1944 - accuracy: 0.9113 - val_loss: 0.8138 - val_accuracy: 0.7702\n",
      "Epoch 134/150\n",
      "234/234 [==============================] - 1s 4ms/step - loss: 0.1863 - accuracy: 0.9109 - val_loss: 0.7513 - val_accuracy: 0.8139\n",
      "Epoch 135/150\n",
      "234/234 [==============================] - 1s 4ms/step - loss: 0.1726 - accuracy: 0.9189 - val_loss: 0.7809 - val_accuracy: 0.7933\n",
      "Epoch 136/150\n",
      "234/234 [==============================] - 1s 4ms/step - loss: 0.1862 - accuracy: 0.9168 - val_loss: 0.8527 - val_accuracy: 0.7920\n",
      "Epoch 137/150\n",
      "234/234 [==============================] - 1s 4ms/step - loss: 0.1965 - accuracy: 0.9100 - val_loss: 0.7896 - val_accuracy: 0.8083\n",
      "Epoch 138/150\n",
      "234/234 [==============================] - 1s 4ms/step - loss: 0.2067 - accuracy: 0.9073 - val_loss: 0.8866 - val_accuracy: 0.7514\n",
      "Epoch 139/150\n",
      "234/234 [==============================] - 1s 4ms/step - loss: 0.2021 - accuracy: 0.9046 - val_loss: 0.7702 - val_accuracy: 0.8096\n",
      "Epoch 140/150\n",
      "234/234 [==============================] - 1s 4ms/step - loss: 0.1804 - accuracy: 0.9179 - val_loss: 0.8512 - val_accuracy: 0.7724\n",
      "Epoch 141/150\n",
      "234/234 [==============================] - 1s 4ms/step - loss: 0.1749 - accuracy: 0.9164 - val_loss: 0.8039 - val_accuracy: 0.8049\n",
      "Epoch 142/150\n",
      "234/234 [==============================] - 1s 4ms/step - loss: 0.1772 - accuracy: 0.9190 - val_loss: 0.8077 - val_accuracy: 0.8049\n",
      "Epoch 143/150\n",
      "234/234 [==============================] - 1s 4ms/step - loss: 0.1785 - accuracy: 0.9145 - val_loss: 0.8789 - val_accuracy: 0.7604\n",
      "Epoch 144/150\n",
      "234/234 [==============================] - 1s 4ms/step - loss: 0.1746 - accuracy: 0.9152 - val_loss: 0.7686 - val_accuracy: 0.8288\n",
      "Epoch 145/150\n",
      "234/234 [==============================] - 1s 3ms/step - loss: 0.1758 - accuracy: 0.9183 - val_loss: 0.8044 - val_accuracy: 0.8023\n",
      "Epoch 146/150\n",
      "234/234 [==============================] - 1s 3ms/step - loss: 0.1755 - accuracy: 0.9180 - val_loss: 0.7602 - val_accuracy: 0.8284\n",
      "Epoch 147/150\n",
      "234/234 [==============================] - 1s 4ms/step - loss: 0.1707 - accuracy: 0.9191 - val_loss: 0.7967 - val_accuracy: 0.8147\n",
      "Epoch 148/150\n",
      "234/234 [==============================] - 1s 4ms/step - loss: 0.1654 - accuracy: 0.9247 - val_loss: 0.7976 - val_accuracy: 0.8293\n",
      "Epoch 149/150\n",
      "234/234 [==============================] - 1s 4ms/step - loss: 0.1706 - accuracy: 0.9222 - val_loss: 0.7641 - val_accuracy: 0.8408\n",
      "Epoch 150/150\n",
      "234/234 [==============================] - 1s 3ms/step - loss: 0.1951 - accuracy: 0.9113 - val_loss: 0.8237 - val_accuracy: 0.8151\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.9381 - accuracy: 0.8029\n",
      "Test Accuracy: 0.802874743938446\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# Define the model\n",
    "model = Sequential([\n",
    "    Dense(128, activation='relu', input_shape=(50,)), \n",
    "    Dense(32, activation='relu', input_shape=(50,)), \n",
    "    Dense(1, activation='sigmoid')  # Sigmoid activation for binary classification\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Summary of the model\n",
    "model.summary()\n",
    "\n",
    "# Calculate class weights to handle class imbalance\n",
    "class_weights = compute_class_weight('balanced', classes=[0, 1], y=y_train)\n",
    "class_weight_dict = {0: class_weights[0], 1: class_weights[1]}\n",
    "\n",
    "# Fit the model with class weights\n",
    "history = model.fit(X_train, y_train, batch_size=40, epochs=150, validation_split=0.2, verbose=1, class_weight=class_weight_dict)\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Accuracy: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 1ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.91      0.89      2481\n",
      "           1       0.28      0.19      0.23       441\n",
      "\n",
      "    accuracy                           0.80      2922\n",
      "   macro avg       0.57      0.55      0.56      2922\n",
      "weighted avg       0.78      0.80      0.79      2922\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "y_pred=model.predict(X_test)\n",
    "threshold = 0.5\n",
    "y_pred_binary = (y_pred >= threshold).astype(int)\n",
    "print(classification_report(y_pred_binary,y_test))\n",
    "classification_report_with_confusion_matrix(y_test,y_pred_binary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('../models/NN_model_1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_26 (Dense)            (None, 128)               6528      \n",
      "                                                                 \n",
      " dense_27 (Dense)            (None, 512)               66048     \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_28 (Dense)            (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_29 (Dense)            (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_10 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_30 (Dense)            (None, 256)               131328    \n",
      "                                                                 \n",
      " dense_31 (Dense)            (None, 64)                16448     \n",
      "                                                                 \n",
      " dense_32 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " dropout_11 (Dropout)        (None, 32)                0         \n",
      "                                                                 \n",
      " dense_33 (Dense)            (None, 16)                528       \n",
      "                                                                 \n",
      " dense_34 (Dense)            (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 748,289\n",
      "Trainable params: 748,289\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/40\n",
      "228/234 [============================>.] - ETA: 0s - loss: 2.6263 - accuracy: 0.9048\n",
      "Epoch 1: saving model to ../checkpoints\\model_epoch_01.h5\n",
      "234/234 [==============================] - 6s 21ms/step - loss: 2.5705 - accuracy: 0.9047 - val_loss: 0.3197 - val_accuracy: 0.9024\n",
      "Epoch 2/40\n",
      "224/234 [===========================>..] - ETA: 0s - loss: 0.3117 - accuracy: 0.9064\n",
      "Epoch 2: saving model to ../checkpoints\\model_epoch_02.h5\n",
      "234/234 [==============================] - 4s 17ms/step - loss: 0.3143 - accuracy: 0.9052 - val_loss: 0.3205 - val_accuracy: 0.9024\n",
      "Epoch 3/40\n",
      "227/234 [============================>.] - ETA: 0s - loss: 0.3166 - accuracy: 0.9043\n",
      "Epoch 3: saving model to ../checkpoints\\model_epoch_03.h5\n",
      "234/234 [==============================] - 4s 16ms/step - loss: 0.3143 - accuracy: 0.9052 - val_loss: 0.3244 - val_accuracy: 0.9024\n",
      "Epoch 4/40\n",
      "234/234 [==============================] - ETA: 0s - loss: 0.3152 - accuracy: 0.9052\n",
      "Epoch 4: saving model to ../checkpoints\\model_epoch_04.h5\n",
      "234/234 [==============================] - 4s 17ms/step - loss: 0.3152 - accuracy: 0.9052 - val_loss: 0.3213 - val_accuracy: 0.9024\n",
      "Epoch 5/40\n",
      "227/234 [============================>.] - ETA: 0s - loss: 0.3137 - accuracy: 0.9055\n",
      "Epoch 5: saving model to ../checkpoints\\model_epoch_05.h5\n",
      "234/234 [==============================] - 4s 17ms/step - loss: 0.3143 - accuracy: 0.9052 - val_loss: 0.3198 - val_accuracy: 0.9024\n",
      "Epoch 6/40\n",
      "230/234 [============================>.] - ETA: 0s - loss: 0.3142 - accuracy: 0.9054\n",
      "Epoch 6: saving model to ../checkpoints\\model_epoch_06.h5\n",
      "234/234 [==============================] - 4s 18ms/step - loss: 0.3147 - accuracy: 0.9052 - val_loss: 0.3201 - val_accuracy: 0.9024\n",
      "Epoch 7/40\n",
      "231/234 [============================>.] - ETA: 0s - loss: 0.3136 - accuracy: 0.9055\n",
      "Epoch 7: saving model to ../checkpoints\\model_epoch_07.h5\n",
      "234/234 [==============================] - 5s 23ms/step - loss: 0.3143 - accuracy: 0.9052 - val_loss: 0.3214 - val_accuracy: 0.9024\n",
      "Epoch 8/40\n",
      "230/234 [============================>.] - ETA: 0s - loss: 0.3142 - accuracy: 0.9050\n",
      "Epoch 8: saving model to ../checkpoints\\model_epoch_08.h5\n",
      "234/234 [==============================] - 5s 23ms/step - loss: 0.3138 - accuracy: 0.9052 - val_loss: 0.3198 - val_accuracy: 0.9024\n",
      "Epoch 9/40\n",
      "231/234 [============================>.] - ETA: 0s - loss: 0.3159 - accuracy: 0.9048\n",
      "Epoch 9: saving model to ../checkpoints\\model_epoch_09.h5\n",
      "234/234 [==============================] - 5s 23ms/step - loss: 0.3149 - accuracy: 0.9052 - val_loss: 0.3201 - val_accuracy: 0.9024\n",
      "Epoch 10/40\n",
      "231/234 [============================>.] - ETA: 0s - loss: 0.3140 - accuracy: 0.9056\n",
      "Epoch 10: saving model to ../checkpoints\\model_epoch_10.h5\n",
      "234/234 [==============================] - 6s 26ms/step - loss: 0.3150 - accuracy: 0.9052 - val_loss: 0.3199 - val_accuracy: 0.9024\n",
      "Epoch 11/40\n",
      "234/234 [==============================] - ETA: 0s - loss: 0.3143 - accuracy: 0.9052\n",
      "Epoch 11: saving model to ../checkpoints\\model_epoch_11.h5\n",
      "234/234 [==============================] - 5s 23ms/step - loss: 0.3143 - accuracy: 0.9052 - val_loss: 0.3215 - val_accuracy: 0.9024\n",
      "Epoch 12/40\n",
      "229/234 [============================>.] - ETA: 0s - loss: 0.3144 - accuracy: 0.9052\n",
      "Epoch 12: saving model to ../checkpoints\\model_epoch_12.h5\n",
      "234/234 [==============================] - 6s 24ms/step - loss: 0.3144 - accuracy: 0.9052 - val_loss: 0.3199 - val_accuracy: 0.9024\n",
      "Epoch 13/40\n",
      "233/234 [============================>.] - ETA: 0s - loss: 0.3144 - accuracy: 0.9052\n",
      "Epoch 13: saving model to ../checkpoints\\model_epoch_13.h5\n",
      "234/234 [==============================] - 5s 24ms/step - loss: 0.3143 - accuracy: 0.9052 - val_loss: 0.3197 - val_accuracy: 0.9024\n",
      "Epoch 14/40\n",
      "231/234 [============================>.] - ETA: 0s - loss: 0.3156 - accuracy: 0.9047\n",
      "Epoch 14: saving model to ../checkpoints\\model_epoch_14.h5\n",
      "234/234 [==============================] - 5s 22ms/step - loss: 0.3144 - accuracy: 0.9052 - val_loss: 0.3201 - val_accuracy: 0.9024\n",
      "Epoch 15/40\n",
      "231/234 [============================>.] - ETA: 0s - loss: 0.3135 - accuracy: 0.9057\n",
      "Epoch 15: saving model to ../checkpoints\\model_epoch_15.h5\n",
      "234/234 [==============================] - 6s 24ms/step - loss: 0.3147 - accuracy: 0.9052 - val_loss: 0.3198 - val_accuracy: 0.9024\n",
      "Epoch 16/40\n",
      "230/234 [============================>.] - ETA: 0s - loss: 0.3147 - accuracy: 0.9049\n",
      "Epoch 16: saving model to ../checkpoints\\model_epoch_16.h5\n",
      "234/234 [==============================] - 5s 22ms/step - loss: 0.3140 - accuracy: 0.9052 - val_loss: 0.3199 - val_accuracy: 0.9024\n",
      "Epoch 17/40\n",
      "232/234 [============================>.] - ETA: 0s - loss: 0.3148 - accuracy: 0.9052\n",
      "Epoch 17: saving model to ../checkpoints\\model_epoch_17.h5\n",
      "234/234 [==============================] - 6s 24ms/step - loss: 0.3147 - accuracy: 0.9052 - val_loss: 0.3201 - val_accuracy: 0.9024\n",
      "Epoch 18/40\n",
      "231/234 [============================>.] - ETA: 0s - loss: 0.3139 - accuracy: 0.9054\n",
      "Epoch 18: saving model to ../checkpoints\\model_epoch_18.h5\n",
      "234/234 [==============================] - 5s 22ms/step - loss: 0.3144 - accuracy: 0.9052 - val_loss: 0.3210 - val_accuracy: 0.9024\n",
      "Epoch 19/40\n",
      "234/234 [==============================] - ETA: 0s - loss: 0.3143 - accuracy: 0.9052\n",
      "Epoch 19: saving model to ../checkpoints\\model_epoch_19.h5\n",
      "234/234 [==============================] - 5s 22ms/step - loss: 0.3143 - accuracy: 0.9052 - val_loss: 0.3207 - val_accuracy: 0.9024\n",
      "Epoch 20/40\n",
      "232/234 [============================>.] - ETA: 0s - loss: 0.3149 - accuracy: 0.9050\n",
      "Epoch 20: saving model to ../checkpoints\\model_epoch_20.h5\n",
      "234/234 [==============================] - 5s 22ms/step - loss: 0.3142 - accuracy: 0.9052 - val_loss: 0.3209 - val_accuracy: 0.9024\n",
      "Epoch 21/40\n",
      "232/234 [============================>.] - ETA: 0s - loss: 0.3149 - accuracy: 0.9051\n",
      "Epoch 21: saving model to ../checkpoints\\model_epoch_21.h5\n",
      "234/234 [==============================] - 5s 23ms/step - loss: 0.3146 - accuracy: 0.9052 - val_loss: 0.3216 - val_accuracy: 0.9024\n",
      "Epoch 22/40\n",
      "233/234 [============================>.] - ETA: 0s - loss: 0.3149 - accuracy: 0.9050\n",
      "Epoch 22: saving model to ../checkpoints\\model_epoch_22.h5\n",
      "234/234 [==============================] - 5s 23ms/step - loss: 0.3145 - accuracy: 0.9052 - val_loss: 0.3205 - val_accuracy: 0.9024\n",
      "Epoch 23/40\n",
      "232/234 [============================>.] - ETA: 0s - loss: 0.3138 - accuracy: 0.9054\n",
      "Epoch 23: saving model to ../checkpoints\\model_epoch_23.h5\n",
      "234/234 [==============================] - 6s 25ms/step - loss: 0.3143 - accuracy: 0.9052 - val_loss: 0.3217 - val_accuracy: 0.9024\n",
      "Epoch 24/40\n",
      "231/234 [============================>.] - ETA: 0s - loss: 0.3142 - accuracy: 0.9054\n",
      "Epoch 24: saving model to ../checkpoints\\model_epoch_24.h5\n",
      "234/234 [==============================] - 6s 24ms/step - loss: 0.3147 - accuracy: 0.9052 - val_loss: 0.3205 - val_accuracy: 0.9024\n",
      "Epoch 25/40\n",
      "230/234 [============================>.] - ETA: 0s - loss: 0.3142 - accuracy: 0.9054\n",
      "Epoch 25: saving model to ../checkpoints\\model_epoch_25.h5\n",
      "234/234 [==============================] - 5s 21ms/step - loss: 0.3147 - accuracy: 0.9052 - val_loss: 0.3219 - val_accuracy: 0.9024\n",
      "Epoch 26/40\n",
      "233/234 [============================>.] - ETA: 0s - loss: 0.3137 - accuracy: 0.9055\n",
      "Epoch 26: saving model to ../checkpoints\\model_epoch_26.h5\n",
      "234/234 [==============================] - 6s 24ms/step - loss: 0.3142 - accuracy: 0.9052 - val_loss: 0.3223 - val_accuracy: 0.9024\n",
      "Epoch 27/40\n",
      "232/234 [============================>.] - ETA: 0s - loss: 0.3142 - accuracy: 0.9054\n",
      "Epoch 27: saving model to ../checkpoints\\model_epoch_27.h5\n",
      "234/234 [==============================] - 5s 23ms/step - loss: 0.3145 - accuracy: 0.9052 - val_loss: 0.3197 - val_accuracy: 0.9024\n",
      "Epoch 28/40\n",
      "230/234 [============================>.] - ETA: 0s - loss: 0.3146 - accuracy: 0.9052\n",
      "Epoch 28: saving model to ../checkpoints\\model_epoch_28.h5\n",
      "234/234 [==============================] - 5s 23ms/step - loss: 0.3146 - accuracy: 0.9052 - val_loss: 0.3197 - val_accuracy: 0.9024\n",
      "Epoch 29/40\n",
      "230/234 [============================>.] - ETA: 0s - loss: 0.3141 - accuracy: 0.9052\n",
      "Epoch 29: saving model to ../checkpoints\\model_epoch_29.h5\n",
      "234/234 [==============================] - 5s 22ms/step - loss: 0.3141 - accuracy: 0.9052 - val_loss: 0.3199 - val_accuracy: 0.9024\n",
      "Epoch 30/40\n",
      "231/234 [============================>.] - ETA: 0s - loss: 0.3147 - accuracy: 0.9052\n",
      "Epoch 30: saving model to ../checkpoints\\model_epoch_30.h5\n",
      "234/234 [==============================] - 5s 21ms/step - loss: 0.3147 - accuracy: 0.9052 - val_loss: 0.3204 - val_accuracy: 0.9024\n",
      "Epoch 31/40\n",
      "234/234 [==============================] - ETA: 0s - loss: 0.3144 - accuracy: 0.9052\n",
      "Epoch 31: saving model to ../checkpoints\\model_epoch_31.h5\n",
      "234/234 [==============================] - 5s 22ms/step - loss: 0.3144 - accuracy: 0.9052 - val_loss: 0.3199 - val_accuracy: 0.9024\n",
      "Epoch 32/40\n",
      "229/234 [============================>.] - ETA: 0s - loss: 0.3136 - accuracy: 0.9057\n",
      "Epoch 32: saving model to ../checkpoints\\model_epoch_32.h5\n",
      "234/234 [==============================] - 5s 21ms/step - loss: 0.3146 - accuracy: 0.9052 - val_loss: 0.3198 - val_accuracy: 0.9024\n",
      "Epoch 33/40\n",
      "230/234 [============================>.] - ETA: 0s - loss: 0.3137 - accuracy: 0.9054\n",
      "Epoch 33: saving model to ../checkpoints\\model_epoch_33.h5\n",
      "234/234 [==============================] - 5s 21ms/step - loss: 0.3141 - accuracy: 0.9052 - val_loss: 0.3205 - val_accuracy: 0.9024\n",
      "Epoch 34/40\n",
      "234/234 [==============================] - ETA: 0s - loss: 0.3148 - accuracy: 0.9052\n",
      "Epoch 34: saving model to ../checkpoints\\model_epoch_34.h5\n",
      "234/234 [==============================] - 5s 21ms/step - loss: 0.3148 - accuracy: 0.9052 - val_loss: 0.3205 - val_accuracy: 0.9024\n",
      "Epoch 35/40\n",
      "233/234 [============================>.] - ETA: 0s - loss: 0.3145 - accuracy: 0.9052\n",
      "Epoch 35: saving model to ../checkpoints\\model_epoch_35.h5\n",
      "234/234 [==============================] - 5s 22ms/step - loss: 0.3144 - accuracy: 0.9052 - val_loss: 0.3198 - val_accuracy: 0.9024\n",
      "Epoch 36/40\n",
      "233/234 [============================>.] - ETA: 0s - loss: 0.3145 - accuracy: 0.9053\n",
      "Epoch 36: saving model to ../checkpoints\\model_epoch_36.h5\n",
      "234/234 [==============================] - 5s 22ms/step - loss: 0.3146 - accuracy: 0.9052 - val_loss: 0.3205 - val_accuracy: 0.9024\n",
      "Epoch 37/40\n",
      "234/234 [==============================] - ETA: 0s - loss: 0.3141 - accuracy: 0.9052\n",
      "Epoch 37: saving model to ../checkpoints\\model_epoch_37.h5\n",
      "234/234 [==============================] - 5s 22ms/step - loss: 0.3141 - accuracy: 0.9052 - val_loss: 0.3199 - val_accuracy: 0.9024\n",
      "Epoch 38/40\n",
      "234/234 [==============================] - ETA: 0s - loss: 0.3143 - accuracy: 0.9052\n",
      "Epoch 38: saving model to ../checkpoints\\model_epoch_38.h5\n",
      "234/234 [==============================] - 5s 22ms/step - loss: 0.3143 - accuracy: 0.9052 - val_loss: 0.3204 - val_accuracy: 0.9024\n",
      "Epoch 39/40\n",
      "234/234 [==============================] - ETA: 0s - loss: 0.3140 - accuracy: 0.9052\n",
      "Epoch 39: saving model to ../checkpoints\\model_epoch_39.h5\n",
      "234/234 [==============================] - 5s 23ms/step - loss: 0.3140 - accuracy: 0.9052 - val_loss: 0.3197 - val_accuracy: 0.9024\n",
      "Epoch 40/40\n",
      "234/234 [==============================] - ETA: 0s - loss: 0.3141 - accuracy: 0.9052\n",
      "Epoch 40: saving model to ../checkpoints\\model_epoch_40.h5\n",
      "234/234 [==============================] - 5s 23ms/step - loss: 0.3141 - accuracy: 0.9052 - val_loss: 0.3199 - val_accuracy: 0.9024\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 0.3346 - accuracy: 0.8956\n",
      "Test Accuracy: 0.8956194519996643\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "# Setup the ModelCheckpoint callback\n",
    "checkpoint = ModelCheckpoint('../checkpoints/model_epoch_{epoch:02d}.h5', \n",
    "                             monitor='val_loss', \n",
    "                             verbose=1, \n",
    "                             save_best_only=False, \n",
    "                             save_weights_only=True, \n",
    "                             mode='auto', \n",
    "                             save_freq='epoch')\n",
    "\n",
    "# Setup the TensorBoard callback\n",
    "logdir = os.path.join(\"../logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "tensorboard_callback = TensorBoard(log_dir=logdir, histogram_freq=1)\n",
    "\n",
    "\n",
    "# Define the model\n",
    "model = Sequential([\n",
    "    Dense(128, activation='relu', input_shape=(50,)), \n",
    "    Dense(512, activation='relu', input_shape=(50,)), \n",
    "    Dropout(0.1),\n",
    "    Dense(512, activation='relu', input_shape=(50,)),\n",
    "    Dropout(0.1), \n",
    "    Dense(512, activation='relu', input_shape=(50,)), \n",
    "    Dropout(0.1),\n",
    "    Dense(256, activation='relu', input_shape=(50,)), \n",
    "    Dense(64, activation='relu', input_shape=(50,)),\n",
    "    Dense(32, activation='relu', input_shape=(50,)), \n",
    "    Dropout(0.1),\n",
    "    Dense(16, activation='relu', input_shape=(50,)), \n",
    "    Dense(1, activation='sigmoid')  # Sigmoid activation for binary classification\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.03), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Summary of the model\n",
    "model.summary()\n",
    "\n",
    "# Fit the model with both callbacks\n",
    "history = model.fit(X_train, y_train, \n",
    "                    batch_size=40, \n",
    "                    epochs=40, \n",
    "                    validation_split=0.2, \n",
    "                    verbose=1, \n",
    "                    callbacks=[checkpoint, tensorboard_callback])\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Accuracy: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 2ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.90      0.94      2854\n",
      "           1       0.11      0.49      0.18        68\n",
      "\n",
      "    accuracy                           0.89      2922\n",
      "   macro avg       0.55      0.69      0.56      2922\n",
      "weighted avg       0.97      0.89      0.93      2922\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "y_pred=model.predict(X_test)\n",
    "threshold = 0.5\n",
    "y_pred_binary = (y_pred >= threshold).astype(int)\n",
    "print(classification_report(y_pred_binary,y_test))\n",
    "classification_report_with_confusion_matrix(y_test,y_pred_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "# Setup the ModelCheckpoint callback\n",
    "checkpoint = ModelCheckpoint('../checkpoints/model_epoch_{epoch:02d}.h5', \n",
    "                             monitor='val_loss', \n",
    "                             verbose=1, \n",
    "                             save_best_only=False, \n",
    "                             save_weights_only=True, \n",
    "                             mode='auto', \n",
    "                             save_freq='epoch')\n",
    "\n",
    "# Setup the TensorBoard callback\n",
    "logdir = os.path.join(\"../logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "tensorboard_callback = TensorBoard(log_dir=logdir, histogram_freq=1)\n",
    "\n",
    "\n",
    "# Define the model\n",
    "model = Sequential([\n",
    "    Dense(128, activation='relu', input_shape=(51,)), \n",
    "    Dropout(0.1),\n",
    "    Dense(16, activation='relu'), \n",
    "    Dense(1, activation='sigmoid')  # Sigmoid activation for binary classification\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Summary of the model\n",
    "model.summary()\n",
    "\n",
    "# Calculate class weights to handle class imbalance\n",
    "class_weights = compute_class_weight('balanced', classes=[0, 1], y=y_train)\n",
    "class_weight_dict = {0: class_weights[0], 1: class_weights[1]}\n",
    "\n",
    "# early_stopping = EarlyStopping(monitor='val_loss', \n",
    "#                                min_delta=0, \n",
    "#                                patience=100,\n",
    "#                                verbose=1, \n",
    "#                                mode='min', \n",
    "#                                baseline=None, \n",
    "#                                restore_best_weights=True)\n",
    "\n",
    "# Fit the model with the callbacks\n",
    "history = model.fit(X_train, y_train, \n",
    "                    batch_size=40, \n",
    "                    epochs=500, \n",
    "                    validation_split=0.2, \n",
    "                    verbose=1, \n",
    "                    class_weight=class_weight_dict,\n",
    "                    callbacks=[checkpoint, tensorboard_callback])\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Accuracy: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 2ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.91      0.88      2446\n",
      "           1       0.29      0.19      0.23       476\n",
      "\n",
      "    accuracy                           0.79      2922\n",
      "   macro avg       0.57      0.55      0.55      2922\n",
      "weighted avg       0.76      0.79      0.77      2922\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "y_pred=model.predict(X_test)\n",
    "threshold = 0.5\n",
    "y_pred_binary = (y_pred >= threshold).astype(int)\n",
    "print(classification_report(y_pred_binary,y_test))\n",
    "classification_report_with_confusion_matrix(y_test,y_pred_binary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results\n",
    "\n",
    "We have used Random Forest classifier and Sequential NN. The NN model performed better than Random Forest in terms of true positive accuracy. However before concluding the point here, further eda will be done on distribution of values, check skewedness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
